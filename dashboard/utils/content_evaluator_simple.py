"""
ê°„ë‹¨í•œ ì½˜í…ì¸  í‰ê°€ì (ì˜ì¡´ì„± ìµœì†Œí™”)
"""

import streamlit as st
from typing import Dict, List, Any
import random

class ContentEvaluator:
    def evaluate_content(self, content: Dict[str, str], product_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€"""
        
        # ê°„ë‹¨í•œ í‰ê°€ ë¡œì§
        score = random.uniform(7.0, 9.5)
        
        if score >= 9.0:
            grade = "A"
        elif score >= 8.0:
            grade = "B"
        elif score >= 7.0:
            grade = "C"
        else:
            grade = "D"
        
        return {
            'total_score': score,
            'grade': grade,
            'engagement_score': random.uniform(7.0, 10.0),
            'readability_score': random.uniform(7.0, 10.0),
            'emotion_score': random.uniform(6.0, 9.0),
            'suggestions': ["ë” ê°ì •ì ì¸ í‘œí˜„ ì¶”ê°€", "í•´ì‹œíƒœê·¸ ìµœì í™”"]
        }

def render_evaluation_results(evaluation: Dict[str, Any]):
    """í‰ê°€ ê²°ê³¼ í‘œì‹œ"""
    st.markdown("#### ğŸ“Š í’ˆì§ˆ í‰ê°€")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ì ", f"{evaluation['total_score']:.1f}/10")
    
    with col2:
        st.metric("ë“±ê¸‰", evaluation['grade'])
    
    with col3:
        st.metric("ì°¸ì—¬ë„", f"{evaluation['engagement_score']:.1f}/10")
    
    with col4:
        st.metric("ê°€ë…ì„±", f"{evaluation['readability_score']:.1f}/10")

def batch_evaluate_contents(contents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ë°°ì¹˜ ì½˜í…ì¸  í‰ê°€"""
    evaluator = ContentEvaluator()
    results = []
    
    for content in contents:
        evaluation = evaluator.evaluate_content(content, {})
        results.append({**content, 'evaluation': evaluation})
    
    return results